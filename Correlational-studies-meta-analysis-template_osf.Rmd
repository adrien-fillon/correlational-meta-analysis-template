---
title: "Construct 1 and 2 meta-analysis"
description: null
output:
  html_document:
    theme: united
    toc: yes
  html_notebook: default
  pdf_document:
    fig_height: 6
    fig_width: 8
  word_document: default
Author: adrien 
---

```{r configuration, include=FALSE}
# Set some key options here

# Metadata to refer to your meta-analysis in the output
Author <- "Lastname"
Year <- 2020
Title <- "Correlational studies meta-analysis"

# This file conducts a meta-analysis of correlational studies. Define the variable names for the relationship of interest
X <- "Construct 1"
Y <- "Construct 2"

# Name of the analysis data file (should be in the same folder as this Rmd file, otherwise specify filepath)
filename <- "Correlational-Studies-Meta-Analysis-Template-coding-sheet_osf.xlsx"

# Code date - determines package versions for reproducibility - set to start of analysis
code_date <- "2023-07-10"
```

This is a RMarkdown template for Correlational studies meta-analysis in Psychology, developed by Adrien Fillon (Ph.D. student) and Dr. Gilad Feldman (Assistant Professor). This is integrated and adapted with reference to Lim and Feldman (2020) and Nanakdewa et al. (2020); experimental meta-analysis template (Yeung et al., 2020), a primer of correlational studies (Quintana, 2015) as well as Fillon et al. (2020) Impact of past behavior normality on regret: Meta-analysis of exceptionality effect. The corresponding datafile is "Correlational-Studies-Meta-Analysis-Template.xlsx" (simulated data). 

For your own analysis, please replace "Variables", Analysis" and "Moderator" with meaningful labels of Cells descriptives column heads, Dependent Variables, Moderators column heads and Moderators categories. In the excel sheet, the box in orange are facultative for the simulation or pretest. To replace efficiently, in RStudio, you can click "edit" then "Replace and find" (or Ctrl+Shift+J). Similarly, in Excel, you can click "Home" then "Find & Select", "Replace", "Replace all".

# Link for the OSF folder : https://osf.io/f85uy/

```{r installpackage, include=FALSE}
# This part is used to set up R: install the packages, load libraries and set formatting options.

# It uses the groundhog package to load package versions from a given date, which is essential for reproducibility (http://datacolada.org/100)
if (!require(groundhog)) install.packages('groundhog')

list_of_packages <- c("readxl", "psychmeta", "TOSTER", "metafor", "tidyverse",
                      "metaviz")

groundhog::groundhog.library(list_of_packages, code_date)

# Set up R environment
Sys.setlocale("LC_ALL", "")
Sys.setenv(LANG = "en")

# Set formatting options : scientific notation and 3 digits.
options(scipen = 999, digits = 3)
```


```{r importfile, include=FALSE}
# Read the datafile. 
# IMPORTANT: 
# i) Please ensure the datafile is in the same folder as this .Rmd file is in (or that file_name includes the path), 
#    otherwise the datafile cannot be read. 
# ii) Please ensure you "skip" the right number of rows so that the datafile can be read properly.  
#    For example, if the headers start at Row 4, type skip = 3.

dataset <- read_excel(filename, sheet = "Main Coding Sheet", skip = 2)

# Create a unique ID for each study and sample
dataset$articlestudy <- paste(
  dataset$Article, "/", dataset$Study, "/",
  dataset$Sample
)
```

# Correlation analyses

This file documents the analyses conducted for `r Author` (`r Year`) *`r Title`*
Analyses were conducted using the file `r filename`, to examine the relationship between `r X` and `r Y`.

# MAIN META ANALYSES

```{r main, include=FALSE}
# For the ma_r function, use the ma_method wanted : "bb" is barebones, "ic" is individual correction and "ad" is artifact distribution. By default, use "ad".
# Change Construct1 and 2 by yours and change rxx and ryy by your reliability coefficients.
# You can change the order displayed by using the argument construct_order = c("Construct1.1", "Construct1.2", "Construct1.3", etc).
# to control for dependency in the same article, one can use check_dependence = TRUE

res_mainanalysis <- ma_r(
  rxyi = dataset$r, n = dataset$N.post, sample_id =
    dataset$articlestudy, ma_method = "ad",
  construct_x = dataset$Construct1, construct_y =
    dataset$Construct2, rxx = dataset$Construct1.reliability,
  ryy = dataset$Construct2.reliability,
  control = control_psychmeta(use_all_arts = TRUE),
  data = dataset
)
res_mainanalysis <- plot_forest(res_mainanalysis)
res_mainanalysis <- sensitivity(res_mainanalysis,
  leave1out = FALSE,
  bootstrap = FALSE
)
metabulate(res_mainanalysis, "results_mainanalysis")

# The metabulate Function above will create an output Word document with all
# the main correlations from the main document
```

Inter-relations
This chunk is used to asses if there are relationships within subfacets of one constructs (for example if you correlate personality traits with something else, here you can assess relationships between the traits).

```{r inter, message=FALSE, warning=FALSE, include=FALSE}
# Running the same analysis, using the correlation in the interrelation sheet.

# Again, remember to skip the correct number of empty rows
datinter <- read_excel(filename, sheet = "Interrelation", skip = 2)

datinter$articlestudy <- paste(
  datinter$Article, "/", datinter$Study,
  "/", datinter$Sample
)

res_inter <- ma_r(
  rxyi = datinter$r, n = datinter$N.post,
  sample_id = datinter$articlestudy, ma_method = "ad",
  construct_x = datinter$`Variable 1`,
  construct_y = datinter$`Variable 2`,
  control = control_psychmeta(use_all_arts = TRUE),
  data = datinter
)
res_inter <- plot_forest(res_inter)
res_inter <- sensitivity(res_inter, leave1out = FALSE, bootstrap = FALSE)
metabulate(res_inter, "results_interrelation")
```

# Moderator analysis
Before conducting a moderator analysis, we have to make sure that there is no relationships between them.
```{r modreg, message=FALSE, warning=FALSE, include=FALSE}

ma_obj_gm <- ma_r(ma_method = "ic",
                  rxyi = dataset$r, n = dataset$N.post,
                  rxx = dataset$Construct1.reliability,
 		  ryy = dataset$Construct2.reliability,
                  moderators = c("Moderator1", "Moderator2"),
                  data = dataset)
ma_obj_gm <- metareg(ma_obj_gm)
ma_obj_gm

```

## Moderator 1

```{r mod1, message=FALSE, warning=FALSE, include=FALSE}
# this chunk will create the same output word document of correlation as in main analysis, with the moderator1 as moderator.
# You can easily create other models by copy-paste this section and change the moderator in the ma_r function. Each time you add a moderator, create a new chunk and change the moderator and the names of the variables.

res_moderator1 <- ma_r(
  rxyi = dataset$r, n = dataset$N.post,
  sample_id = dataset$articlestudy, ma_method = "ad",
  construct_x = dataset$Construct1,
  construct_y = dataset$Construct2,
  rxx = dataset$Construct1.reliability,
  ryy = dataset$Construct2.reliability,
  moderators = Moderator1,
  control = control_psychmeta(use_all_arts = TRUE),
  data = dataset
)
res_moderator1 <- plot_forest(res_moderator1)
res_moderator1 <- sensitivity(res_moderator1,
  leave1out = FALSE,
  bootstrap = FALSE
)
metabulate(res_moderator1, "results_moderator1")
```

## Publication.Status 

1 = Published
0 = Unpublished


```{r pubstatus, message=FALSE, warning=FALSE, include=FALSE}
# This chunk is using publication status as moderator. This will be used for analysis of possible publication bias due to file-drawer problem.It will create a word output of all the correlations will two levels = published and unpublished to see if the publication status influences the results.

res_pubstat <- ma_r(
  rxyi = dataset$r, n = dataset$N.post,
  sample_id = dataset$articlestudy, ma_method = "ad",
  construct_x = dataset$Construct1,
  construct_y = dataset$Construct2,
  rxx = dataset$Construct1.reliability,
  ryy = dataset$Construct2.reliability,
  moderators = Publication.Status,
  control = control_psychmeta(use_all_arts = TRUE),
  data = dataset
)
res_pubstat <- plot_forest(res_pubstat)
res_pubstat <- sensitivity(res_pubstat, leave1out = FALSE, bootstrap = FALSE)
metabulate(res_pubstat, "results_pubstatus")
```

# Plots

```{r plots, echo=FALSE, message=FALSE, warning=FALSE}
# This chunk will create forest plots and cumulative meta-analysis plots.
# To change the variables plotted, set `ma_obj` to the appropriate meta-analyis
# results (res_mainanalysis, res_moderator1, res_pubstat) and `variables` to a vector for the desired construct pair--for example, `c("Construct1.1", "Construct2.1")`.

ma_obj <- res_mainanalysis
variables <- c("Construct1.1", "Construct2.1")
get_plots(ma_obj,
  analyses = list(construct_pair = list(variables)),
  plot_types = "forest"
)$forest[[1]]$moderated$barebones


# Idem for viewing cumulative meta-analysis plots

ma_obj <- res_mainanalysis
variables <- c("Construct1.1", "Construct2.1")
get_plots(ma_obj,
  analyses = list(construct_pair = list(variables)),
  plot_types = "cumulative"
)$cumulative[[1]]$artifact_distribution$true_score$plots
```

# Equivalence test

```{r et, echo=FALSE, message=FALSE, warning=FALSE}
# This chunk is only of use if you want to test equivalence for a specific correlation.

# Use N in the meta-analysis as n, r as the mean true-score correlation, and lower and higer bound as your choice.
#  benchmarks for low/medium/high effect are r = .1, r = .3, and r = .5 (Lakens, 2017)

# TOSTr(n, r, low_eqbound_r, high_eqbound_r, alpha, plot = TRUE, verbose = TRUE)

# here is an example
# TOSTr(n = 5843, r = .34, low_eqbound_r = 0.27, high_eqbound_r = .42, alpha=0.5, plot = TRUE, verbose = TRUE)
```

# Power of studies included in the analysis
```{r power, echo=FALSE, message=FALSE, warning=FALSE}
# This chunk will help you create a sunset plot to view the power of every studies in the meta-anaysis depending of the correlation observed.
# We create the dataset.
dataset <- escalc(
  measure = "ZCOR", ri = r,
  ni = N.post, data = dataset, append = TRUE
)

# Change filter based on the power calculation you want to make. Here is the example for Construct1.1.

dat <- dataset %>%
  filter(Construct1 == "Construct1.1") %>%
  select(articlestudy, yi, vi)

# we create a meta-analysis object
res <- rma.uni(yi, vi, data = dat)
# and we vizualize the power of the analysis.
viz_sunset(res,
  contours = TRUE,
  power_contours = "continuous"
)

# One can also add the argument true_effect = 0.XX for the minimal effect size of interest.
```

# Mean reliability scale (for supplementary)

```{r RS, echo=FALSE, message=FALSE, warning=FALSE}
# This chunk will help you create a mean reliability scale table that can replace the empty one in supplementary in order to assess the quality of the scales we used.

# the internal psychmeta function summarize_ads can summarize the mean and variance of artifact distribution.
# for an understanding of this table, see Wiernik & Dahlke (2019).

# The amount of measurement error in a sample of scores is quantified using a reliability coefficient, defined as the proportion of the observed-score variance that is consistent (i.e., believed to be “true”). Conceptually, the reliability coefficient is the correlation between two parallel measures of a construct. The square root of the reliability coefficient also called the measurement quality index; Schmidt & Hunter, 2015) is the correlation between the measured (observed) variable and its underlying latent variable.

knitr::kable(
  adrien <- psychmeta:::summarize_ads(res_mainanalysis) %>%
    filter(Artifact %in% c("rxxi_irr", "qxi_irr")) %>%
    as_tibble() %>%
    mutate(
      k_total = format_num(.$k_total, digits = 0),
      N_total = format_num(.$N_total, digits = 0),
      mean = format_num(.$mean, digits = 3),
      sd = format_num(.$sd, digits = 3),
      sd_res = format_num(.$sd_res, digits = 3)
    )
)
```

# Other functions

```{r other, echo=FALSE, message=FALSE, warning=FALSE}
# This chunk gives you other functions that can be of your interest in conducting a meta-analysis with psychmeta.

# you can easily transform stats to correlation coefficient by using

# convert_es(es = 1,    input_es = "d",       output_es = "r", n1 = 50,  n2 = 50)
# input_es can be of the form "r", "d", "F", "chisq", "p.chisq", "or", "lor" and output_es = "r" or "d"

# Also, it is possible to make multiple transformation at a time, form example a whole column

# convert_es(es = c(.4, .3, .25),input_es = "r", output_es = "d", n1 = c(50, 110, 65), n2 = c(50, 70, 65))
```

# Many more possibilities from Psychmeta : https://cran.r-project.org/web/packages/psychmeta/vignettes/overview.html
# Dahlke, J. A., & Wiernik, B. M. (2019). psychmeta: An R package for psychometric meta-analysis. Applied Psychological Measurement, 43(5), 415-416. https://doi.org/10.1177/0146621618795933
